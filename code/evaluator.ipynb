{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "evaluator.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJwmY4a5zco5",
        "outputId": "60e31c00-a91f-40b0-d726-80aa15dfb51d"
      },
      "source": [
        "!pip install tldextract"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tldextract in /usr/local/lib/python3.7/dist-packages (3.1.0)\n",
            "Requirement already satisfied: requests-file>=1.4 in /usr/local/lib/python3.7/dist-packages (from tldextract) (1.5.1)\n",
            "Requirement already satisfied: requests>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from tldextract) (2.23.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.7/dist-packages (from tldextract) (2.10)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from tldextract) (3.0.12)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from requests-file>=1.4->tldextract) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.1.0->tldextract) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.1.0->tldextract) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.1.0->tldextract) (2020.12.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7HYosOLwaMT"
      },
      "source": [
        "import pandas as pd\n",
        "import tldextract"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mp0-iEwqzswh"
      },
      "source": [
        "tecknology_domain = [\n",
        "\"addtoany\", \n",
        "\"adobe\", \n",
        "\"computerhope\", \n",
        "\"computerlanguage\", \n",
        "\"eurid\", \n",
        "\"google\", \n",
        "\"mediawiki\",\n",
        "\"merlot\",\n",
        "\"oercommons\",\n",
        "\"pc\"]\n",
        "\n",
        "bussiness_domain=[\n",
        "\"hbr\",\n",
        "\"philadelphiabusinesslist\"]\n",
        "\n",
        "politics_domain=[\n",
        "\"newpol\"]\n",
        "\n",
        "domain_history=[\n",
        "\"historic-uk\",\n",
        "\"newworldencyclopedia\",\n",
        "\"worldhistory\",\n",
        "\"ushistory\"]\n",
        "\n",
        "# loc missouri reddit reimagine-education twitter pod sharpened ox slj         tutorful tutorhouse     wisc\n",
        "\n",
        "total = 0\n",
        "total_urls = 0\n",
        "tech_match = 0\n",
        "tech_miss_match = 0\n",
        "label_cnt = 0\n",
        "n_a = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZ1UIwEpwnMe",
        "outputId": "78f7bf58-0299-4504-fc04-482d4fce40c8"
      },
      "source": [
        "csv_file = \"/content/drive/MyDrive/crawler/Spider1/results.csv\"\n",
        "df = pd.read_csv(csv_file,index_col=False)\n",
        "for i in range(0,len(df.index)):\n",
        "  domain = tldextract.extract(df.loc[i,\"link\"]).domain\n",
        "  # print(domain)\n",
        "  total_urls = total_urls +1\n",
        "  if df.loc[i,\"processed\"]== \"Yes\":\n",
        "    total = total +1\n",
        "    if domain in tecknology_domain and df.loc[i,\"label\"].split(':')[0] == \"technology\":\n",
        "      label_cnt = label_cnt +1 \n",
        "      tech_match = tech_match + 1 \n",
        "      df.loc[i,\"true_label\"]=\"technology\"\n",
        "    elif domain in tecknology_domain and df.loc[i,\"label\"].split(':')[0] != \"technology\":\n",
        "      label_cnt = label_cnt +1 \n",
        "      tech_miss_match = tech_miss_match +1 \n",
        "      df.loc[i,\"true_label\"]=\"technology\"\n",
        "    elif domain not in tecknology_domain:\n",
        "      n_a = n_a + 1\n",
        "      # print(f\"N/A -- {domain}\")\n",
        "\n",
        "\n",
        "print(f\"results: total = {total} label:{label_cnt}, tech_match = {tech_match} , tech_miss_match = {tech_miss_match}, n_a = {n_a}\")\n",
        "print(f\"total_urls: {total_urls} \")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "results: total = 440 label:82, tech_match = 82 , tech_miss_match = 0, n_a = 82\n",
            "total_urls: 440 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETw4J9fRECya",
        "outputId": "a64e3449-d660-4952-bd64-b399d33465c7"
      },
      "source": [
        "csv_file = \"/content/drive/MyDrive/crawler/Spider1/results.csv\"\n",
        "df = pd.read_csv(csv_file,index_col=False)\n",
        "for i in range(0,len(df.index)):\n",
        "  domain = tldextract.extract(df.loc[i,\"link\"]).domain\n",
        "  # print(domain)\n",
        "  total_urls = total_urls +1\n",
        "  if df.loc[i,\"processed\"]== \"Yes\":\n",
        "    total = total +1\n",
        "    if domain in domain_history and df.loc[i,\"label\"].split(':')[0] == \"history\":\n",
        "      label_cnt = label_cnt +1 \n",
        "      tech_match = tech_match + 1 \n",
        "      df.loc[i,\"true_label\"]=\"history\"\n",
        "    elif domain in domain_history and df.loc[i,\"label\"].split(':')[0] != \"history\":\n",
        "      label_cnt = label_cnt +1 \n",
        "      tech_miss_match = tech_miss_match +1 \n",
        "      df.loc[i,\"true_label\"]=\"history\"\n",
        "    elif domain not in domain_history:\n",
        "      n_a = n_a + 1\n",
        "      # print(f\"N/A -- {domain}\")\n",
        "\n",
        "\n",
        "print(f\"results: total = {total} label:{label_cnt}, tech_match = {tech_match} , tech_miss_match = {tech_miss_match}, n_a = {n_a}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "results: total = 609 label:244, tech_match = 115 , tech_miss_match = 129, n_a = 365\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lliPdAvFDZZ",
        "outputId": "0d4a4432-4572-4728-b54c-ab5d8a82c405"
      },
      "source": [
        "csv_file = \"/content/drive/MyDrive/crawler/Spider1/results.csv\"\n",
        "df = pd.read_csv(csv_file,index_col=False)\n",
        "for i in range(0,len(df.index)):\n",
        "  domain = tldextract.extract(df.loc[i,\"link\"]).domain\n",
        "  # print(domain)\n",
        "  total_urls = total_urls +1\n",
        "  if df.loc[i,\"processed\"]== \"Yes\":\n",
        "    total = total +1\n",
        "    if domain in bussiness_domain and df.loc[i,\"label\"].split(':')[0] == \"business\":\n",
        "      label_cnt = label_cnt +1 \n",
        "      tech_match = tech_match + 1 \n",
        "      df.loc[i,\"true_label\"]=\"business\"\n",
        "    elif domain in bussiness_domain and df.loc[i,\"label\"].split(':')[0] != \"business\":\n",
        "      label_cnt = label_cnt +1 \n",
        "      tech_miss_match = tech_miss_match +1 \n",
        "      df.loc[i,\"true_label\"]=\"business\"\n",
        "    elif domain not in bussiness_domain:\n",
        "      n_a = n_a + 1\n",
        "      # print(f\"N/A -- {domain}\")\n",
        "\n",
        "\n",
        "print(f\"results: total = {total} label:{label_cnt}, tech_match = {tech_match} , tech_miss_match = {tech_miss_match}, n_a = {n_a}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "results: total = 609 label:61, tech_match = 58 , tech_miss_match = 3, n_a = 548\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PezfS_gZFWt3",
        "outputId": "a1abdef8-c176-4427-a1f5-ccb0f4efbbc9"
      },
      "source": [
        "csv_file = \"/content/drive/MyDrive/crawler/Spider1/results.csv\"\n",
        "df = pd.read_csv(csv_file,index_col=False)\n",
        "for i in range(0,len(df.index)):\n",
        "  domain = tldextract.extract(df.loc[i,\"link\"]).domain\n",
        "  # print(domain)\n",
        "  total_urls = total_urls +1\n",
        "  if df.loc[i,\"processed\"]== \"Yes\":\n",
        "    total = total +1\n",
        "    if domain in politics_domain and df.loc[i,\"label\"].split(':')[0] == \"politics\":\n",
        "      label_cnt = label_cnt +1 \n",
        "      tech_match = tech_match + 1 \n",
        "      df.loc[i,\"true_label\"]=\"politics\"\n",
        "    elif domain in politics_domain and df.loc[i,\"label\"].split(':')[0] != \"politics\":\n",
        "      label_cnt = label_cnt +1 \n",
        "      tech_miss_match = tech_miss_match +1 \n",
        "      df.loc[i,\"true_label\"]=\"politics\"\n",
        "    elif domain not in politics_domain:\n",
        "      n_a = n_a + 1\n",
        "      # print(f\"N/A -- {domain}\")\n",
        "\n",
        "\n",
        "print(f\"results: total = {total} label:{label_cnt}, tech_match = {tech_match} , tech_miss_match = {tech_miss_match}, n_a = {n_a}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "results: total = 609 label:51, tech_match = 38 , tech_miss_match = 13, n_a = 558\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJFOWfR-5uA5"
      },
      "source": [
        "with open(csv_file, 'w') as f:\n",
        "  df.to_csv(f,index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}